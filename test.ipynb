{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FancyMLP(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FancyMLP, self).__init__(**kwargs)\n",
    "\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False) # 不可训练参数（常数参数）\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        # 使用创建的常数参数，以及nn.functional中的relu函数和mm函数\n",
    "        x = nn.functional.relu(torch.mm(x, self.rand_weight.data) + 1)\n",
    "\n",
    "        # 复用全连接层。等价于两个全连接层共享参数\n",
    "        x = self.linear(x)\n",
    "        # 控制流，这里我们需要调用item函数来返回标量进行比较\n",
    "        while x.norm().item() > 1:\n",
    "            x /= 2\n",
    "        if x.norm().item() < 0.8:\n",
    "            x *= 10\n",
    "        return x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NestMLP, self).__init__(**kwargs)\n",
    "        self.net = nn.Sequential(nn.Linear(40, 30), nn.ReLU()) \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "net = nn.Sequential(NestMLP(), nn.Linear(30, 20), FancyMLP())\n",
    "\n",
    "net1 = nn.Sequential(nn.Linear(5,5))\n",
    "\n",
    "x = torch.rand(3,5)\n",
    "\n",
    "net1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Linear(3, 2)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.act(self.hidden(x))\n",
    "        return self.output(a)\n",
    "\n",
    "net = MLP()\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "x = torch.tensor([1,2,3]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数（“多输入通道和多输出通道”一节将介绍）均为1\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    print(X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])  # 排除不关心的前两维：批量和通道\n",
    "\n",
    "# 注意这里是两侧分别填充1行或列，所以在两侧一共填充2行或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((1,1)+(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[[ 0.,  1.,  2.,  3.],\n",
    "          [ 4.,  5.,  6.,  7.],\n",
    "          [ 8.,  9., 10., 11.],\n",
    "          [12., 13., 14., 15.]],\n",
    "\n",
    "         [[ 1.,  2.,  3.,  4.],\n",
    "          [ 5.,  6.,  7.,  8.],\n",
    "          [ 9., 10., 11., 12.],\n",
    "          [13., 14., 15., 16.]]]])\n",
    "\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "        nn.Linear(10, 20),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(20, 15), \n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(15, 10)\n",
    "        )\n",
    "\n",
    "x = torch.rand(20, 10)\n",
    "\n",
    "for name, c in net.named_children():\n",
    "    x = c(x)\n",
    "    print(name,\"______\", x.shape)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.mean(dim=0, keepdim=True).mean(dim=1, keepdim=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def conv_block(in_channels, out_channels):\n",
    "    blk = nn.Sequential(nn.BatchNorm2d(in_channels), \n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "    return blk\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, in_channels, out_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        net = []\n",
    "        for i in range(num_convs):\n",
    "            in_c = in_channels + i * out_channels\n",
    "            net.append(conv_block(in_c, out_channels))\n",
    "        self.net = nn.ModuleList(net)\n",
    "        self.out_channels = in_channels + num_convs * out_channels # 计算输出通道数\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            X = torch.cat((X, Y), dim=1)  # 在通道维上将输入和输出连结\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blk = DenseBlock(2,3,8)\n",
    "x = torch.rand(4,3,8,8)\n",
    "y = blk(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:6,0:9].T.reshape(-1,2)\n",
    "objp *= 1.2\n",
    "objp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "img = cv.imread('test.jpg')\n",
    "cv.imshow('im', img)\n",
    "cv.waitKey(500)\n",
    "img = cv.resize(img, (960,480))\n",
    "print(img.size)\n",
    "cv.imshow('im', img)\n",
    "cv.waitKey(500)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "objp = np.zeros((1, 6*9, 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:6, 0:9].T.reshape(-1, 2)*30\n",
    "objp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "a = '[sdsad]'\n",
    "a = re.sub('[\\[\\]sd]', '', a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"a  b\"\n",
    "print(a.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in range(10)]\n",
    "a = np.array(a)\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '1.2'\n",
    "print(float(a))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['851.19446', '631.96454', '850.45294', '606.37787', '849.7779', '581.1345', '849.17004', '556.3839', '848.73193', '532.3114', '848.3455', '509.43277', '875.5562', '630.39233', '874.6188', '604.2248', '873.6532', '578.63226', '872.7132', '553.72205', '872.0637', '529.46063', '871.3059', '506.33194', '901.02075', '628.0922', '899.38934', '602.03986', '898.2486', '576.4682', '896.7754', '551.0553', '895.75024', '526.63934', '894.55145', '503.14148', '927.0404', '626.06226', '925.35785', '599.6164', '923.547', '573.5644', '921.6574', '548.41016', '920.4528', '523.55316', '918.9476', '499.83658', '953.38477', '623.7945', '951.58124', '596.8947', '949.3174', '570.51416', '947.2819', '545.4884', '945.32825', '520.51636', '943.47253', '496.54892', '980.31006', '621.4369', '977.5882', '594.5057', '975.329', '568.1034', '972.91986', '542.20905', '970.4433', '517.46344', '968.1454', '493.29834', '1007.5476', '618.5754', '1004.6684', '591.5659', '1001.9089', '564.9984', '999.2292', '539.5562', '996.4984', '514.5286', '993.44904', '490.38174', '1034.9849', '615.74475', '1031.6824', '588.5247', '1028.7372', '562.0436', '1025.3925', '536.2487', '1021.7842', '511.08374', '1018.5763', '487.5063', '1062.0992', '612.7502', '1058.5757', '585.5391', '1055.3615', '559.03516', '1051.6493', '533.08014', '1047.5045', '508.42755', '1043.844', '484.31967']\n",
    "for i in a:\n",
    "    print(i, float(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "res = {'a':1, 'b':2}\n",
    "\n",
    "with open('camera_parameter.yaml') as f:\n",
    "\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(5000).reshape(100,50,1)\n",
    "print(a.shape[::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2],[3,4]]\n",
    "b = [[-1,-2]]\n",
    "import numpy as np\n",
    "np.array(a) + np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = [[[1,2]],[[1,2]],[[1,2]]]\n",
    "b = np.array(a)\n",
    "# b.shape\n",
    "b.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.resize(3,2,1)\n",
    "b.shape[:2][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "src = [[650,967],[1209,961],[801,753],[1112,735]]\n",
    "src = np.array(src)\n",
    "src =src - np.array([0,540])\n",
    "src[:, 1] = np.array([540])-src[:, 1]\n",
    "print(src)\n",
    "center = (np.average(src[:, 0]), np.average(src[:, 1]))\n",
    "print('     ', center)\n",
    "\n",
    "bias = (src - np.array(center))*0.2\n",
    "for i in range(len(bias)):\n",
    "    for j in range(len(bias[0])):\n",
    "        bias[i][j] = math.floor(bias[i][j])\n",
    "\n",
    "print(bias)\n",
    "\n",
    "print(bias+src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 763.3812   684.4941 ]]\n",
      "\n",
      " [[ 758.9092   635.788  ]]\n",
      "\n",
      " [[ 756.0631   584.9381 ]]\n",
      "\n",
      " [[ 754.45026  532.5921 ]]\n",
      "\n",
      " [[ 753.59033  480.24738]]\n",
      "\n",
      " [[ 754.7303   428.6049 ]]\n",
      "\n",
      " [[ 810.4393   687.5122 ]]\n",
      "\n",
      " [[ 806.8684   637.64105]]\n",
      "\n",
      " [[ 804.4364   585.5024 ]]\n",
      "\n",
      " [[ 802.8525   531.98834]]\n",
      "\n",
      " [[ 802.29755  478.32098]]\n",
      "\n",
      " [[ 803.0064   425.66943]]\n",
      "\n",
      " [[ 860.3572   689.5749 ]]\n",
      "\n",
      " [[ 857.75336  638.8936 ]]\n",
      "\n",
      " [[ 855.4756   585.7337 ]]\n",
      "\n",
      " [[ 854.3776   531.38354]]\n",
      "\n",
      " [[ 854.023    476.56226]]\n",
      "\n",
      " [[ 854.2095   422.5851 ]]\n",
      "\n",
      " [[ 912.72675  690.787  ]]\n",
      "\n",
      " [[ 911.14374  639.6444 ]]\n",
      "\n",
      " [[ 909.64557  586.15375]]\n",
      "\n",
      " [[ 908.7993   530.4066 ]]\n",
      "\n",
      " [[ 908.34     475.33707]]\n",
      "\n",
      " [[ 908.28     420.71335]]\n",
      "\n",
      " [[ 965.8736   691.03406]]\n",
      "\n",
      " [[ 965.555    639.66113]]\n",
      "\n",
      " [[ 965.01984  585.72455]]\n",
      "\n",
      " [[ 964.4837   530.02454]]\n",
      "\n",
      " [[ 963.8972   474.30927]]\n",
      "\n",
      " [[ 963.3789   419.7228 ]]\n",
      "\n",
      " [[1019.36554  690.3099 ]]\n",
      "\n",
      " [[1019.9725   638.8392 ]]\n",
      "\n",
      " [[1020.214    585.03253]]\n",
      "\n",
      " [[1020.0308   529.51666]]\n",
      "\n",
      " [[1019.5142   474.00192]]\n",
      "\n",
      " [[1018.5879   419.35986]]\n",
      "\n",
      " [[1072.3733   688.4686 ]]\n",
      "\n",
      " [[1073.8394   637.38965]]\n",
      "\n",
      " [[1075.0337   584.13196]]\n",
      "\n",
      " [[1075.2839   528.9252 ]]\n",
      "\n",
      " [[1074.7067   474.1222 ]]\n",
      "\n",
      " [[1073.3043   420.06757]]\n",
      "\n",
      " [[1122.5157   685.52893]]\n",
      "\n",
      " [[1125.4695   635.44794]]\n",
      "\n",
      " [[1127.013    582.65875]]\n",
      "\n",
      " [[1127.5863   528.72986]]\n",
      "\n",
      " [[1127.4071   474.3917 ]]\n",
      "\n",
      " [[1125.3561   421.77292]]\n",
      "\n",
      " [[1170.72     681.79895]]\n",
      "\n",
      " [[1173.6742   632.7388 ]]\n",
      "\n",
      " [[1175.8608   581.22986]]\n",
      "\n",
      " [[1177.1025   528.3547 ]]\n",
      "\n",
      " [[1176.4294   475.48907]]\n",
      "\n",
      " [[1174.4213   423.48856]]]\n",
      "[[[ 763.4075   684.6285 ]]\n",
      "\n",
      " [[ 759.2313   635.6851 ]]\n",
      "\n",
      " [[ 756.15405  584.8235 ]]\n",
      "\n",
      " [[ 754.35504  532.5449 ]]\n",
      "\n",
      " [[ 753.7663   480.33575]]\n",
      "\n",
      " [[ 754.67633  428.6092 ]]\n",
      "\n",
      " [[ 810.43176  687.5156 ]]\n",
      "\n",
      " [[ 806.8941   637.60376]]\n",
      "\n",
      " [[ 804.4159   585.53125]]\n",
      "\n",
      " [[ 802.6655   531.8405 ]]\n",
      "\n",
      " [[ 802.31775  478.28   ]]\n",
      "\n",
      " [[ 802.8413   425.47278]]\n",
      "\n",
      " [[ 860.33295  689.61536]]\n",
      "\n",
      " [[ 857.6392   638.9319 ]]\n",
      "\n",
      " [[ 855.59125  585.8337 ]]\n",
      "\n",
      " [[ 854.4285   531.3477 ]]\n",
      "\n",
      " [[ 853.9422   476.53342]]\n",
      "\n",
      " [[ 854.34265  422.6621 ]]\n",
      "\n",
      " [[ 912.5941   690.78845]]\n",
      "\n",
      " [[ 911.088    639.5838 ]]\n",
      "\n",
      " [[ 909.6784   585.9857 ]]\n",
      "\n",
      " [[ 908.70044  530.49164]]\n",
      "\n",
      " [[ 908.37976  475.3501 ]]\n",
      "\n",
      " [[ 908.30176  420.64236]]\n",
      "\n",
      " [[ 965.96747  691.0665 ]]\n",
      "\n",
      " [[ 965.5061   639.5847 ]]\n",
      "\n",
      " [[ 964.85205  585.6364 ]]\n",
      "\n",
      " [[ 964.41473  530.0222 ]]\n",
      "\n",
      " [[ 963.7729   474.37967]]\n",
      "\n",
      " [[ 963.3948   419.6146 ]]\n",
      "\n",
      " [[1019.4751   690.2896 ]]\n",
      "\n",
      " [[1019.9797   638.7498 ]]\n",
      "\n",
      " [[1020.3718   585.10516]]\n",
      "\n",
      " [[1020.185    529.46454]]\n",
      "\n",
      " [[1019.5388   473.92755]]\n",
      "\n",
      " [[1018.5533   419.4341 ]]\n",
      "\n",
      " [[1072.3447   688.3976 ]]\n",
      "\n",
      " [[1073.8622   637.4447 ]]\n",
      "\n",
      " [[1074.9504   584.1455 ]]\n",
      "\n",
      " [[1075.2589   529.0891 ]]\n",
      "\n",
      " [[1074.555    474.17236]]\n",
      "\n",
      " [[1073.3337   420.11472]]\n",
      "\n",
      " [[1122.7507   685.46185]]\n",
      "\n",
      " [[1125.4972   635.42584]]\n",
      "\n",
      " [[1127.053    582.73035]]\n",
      "\n",
      " [[1127.5319   528.66254]]\n",
      "\n",
      " [[1127.1133   474.56506]]\n",
      "\n",
      " [[1125.3346   421.50757]]\n",
      "\n",
      " [[1170.5574   681.7453 ]]\n",
      "\n",
      " [[1173.811    632.67645]]\n",
      "\n",
      " [[1175.9541   581.3428 ]]\n",
      "\n",
      " [[1177.0441   528.4341 ]]\n",
      "\n",
      " [[1176.4607   475.5275 ]]\n",
      "\n",
      " [[1174.4739   423.50684]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "img = cv2.imread(\"./10.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, corners = cv2.findChessboardCorners(gray, (6,9), cv2.CALIB_CB_FAST_CHECK)\n",
    "\n",
    "if ret:\n",
    "    print(corners)\n",
    "    # for i in range(len(corners)):\n",
    "    #     a = tuple([math.floor(i) for i in corners[i].squeeze()])\n",
    "    #     cv2.putText(img, str(i), a, cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,0,0),2,cv2.LINE_AA)\n",
    "    corners2 = cv2.cornerSubPix(gray,corners, \n",
    "                    (11,11), \n",
    "                    (-1,-1), \n",
    "                    (cv2.TERM_CRITERIA_EPS + \n",
    "                    cv2.TERM_CRITERIA_MAX_ITER, 30, 0.01))\n",
    "    print(corners2)\n",
    "\n",
    "# cv2.imshow(\"hah\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7741/2310045878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./1.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yaml'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import yaml\n",
    "\n",
    "\n",
    "a = cv2.imread(\"./1.jpg\")\n",
    "a = cv2.resize(a,(640,480),interpolation=cv2.INTER_CUBIC)\n",
    "print(a.shape)\n",
    "cv2.imshow(\"s\",a)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 22 18:31:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 40%   24C    P8    15W / 130W |    486MiB /  8192MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1301      G   /usr/bin/gnome-shell               88MiB |\n",
      "|    0   N/A  N/A      2050      G   /usr/lib/xorg/Xorg                162MiB |\n",
      "|    0   N/A  N/A      2181      G   /usr/bin/gnome-shell               34MiB |\n",
      "|    0   N/A  N/A      2754      G   ...veSuggestionsOnlyOnDemand       31MiB |\n",
      "|    0   N/A  N/A      3185      G   ...448922314048391487,131072       61MiB |\n",
      "|    0   N/A  N/A      8072      G   ...AAAAAAAAA= --shared-files       95MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0160655bc99dbda78ced2dbc399d18032bd95b955ed82206ef2af97e4ab4c91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
